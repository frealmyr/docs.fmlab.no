{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to my tech blog! \ud83d\ude4c \u00b6 This is where i post tutorials, tips and tricks for homelabs and cloud infrastructure, whenever i feel a writer's itch. This site is hosted on github pages, with a github action that automagically builds mkdocs and deploys it with github actions . If you find any errors, or want to request changes, you can use this repository's issue tracker .","title":"Home"},{"location":"#welcome-to-my-tech-blog","text":"This is where i post tutorials, tips and tricks for homelabs and cloud infrastructure, whenever i feel a writer's itch. This site is hosted on github pages, with a github action that automagically builds mkdocs and deploys it with github actions . If you find any errors, or want to request changes, you can use this repository's issue tracker .","title":"Welcome to my tech blog! \ud83d\ude4c"},{"location":"homelab/","text":"Homelab \u00b6 This is where the magic happens","title":"Homelab"},{"location":"homelab/#homelab","text":"This is where the magic happens","title":"Homelab"},{"location":"homelab/docker/rootless-docker/","text":"\u26a0\ufe0f DEPRECATED \u26a0\ufe0f \u00b6 I wrote this post back in 2020, Podman wasn't an alternative back then. Its mature now and I do recommend it, keeping this post as reminder for the headaches I encountered with rootless docker. Rootless Docker \u00b6 The default way to install docker is to grab the latest debian package and install it on your host using your root user. Docker will then run the daemon, containers, volumes and everything else as root . If a container is configured without any security measures and is running as root while it's publicly available. It could be a potential attack vector for gaining root access to the underlying host operating system . With these things in mind, i've recently been trying out the experimental rootless docker mode . Where the concept is to execute the Docker daemon and containers inside a user namespace, instead of running everything as root. There are however some limitations while going rootless , as the following features are not supported: AppArmor Checkpoint (Experimental) Overlay network driver Exposing SCTP ports Cgroups (hardware limits, docker top ) Non-debian based OS only supports vfs graphdriver which is considered suboptimal for many filesystems. (Overlay2 out-of-the-box on Ubuntu) One key advantage to rootless, is the ability to run docker containers inside a user namespace. Which means that you can in theory create dedicated users or groups for docker containers and make use of the host systems UIDs/GIDs for restricting access to files and features. The rootless Docker mode is still in a experimental stage. While it works rather well on my system, some bugs might arise in the future. Earlier issues like low network throughput has been fixed , so if you decide to use rootless Docker, please report any bugs or issues that you might have discovered to the relevant repositories. Installing rootless docker \u00b6 First we need to install the dependency uidmap which is needed to allow multiple UIDs/GIDs to be used in the user namespace. 1 sudo apt update && sudo apt install -f curl uidmap Now we can fetch and install the latest stable release of the rootless install script. 1 curl -fsSL https://get.docker.com/rootless | sh When the install script finishes, the output will provide some environment variable exports that will be needed by the docker-cli for connecting to the rootless docker daemon. If you run cat ~/.profile , you can see that Ubuntu automatically adds ${HOME}/bin to $PATH if the folder exists. So there is no need to add this to path manually. So we only need to add the DOCKER_HOST environment variable to our profile. 1 echo \"export DOCKER_HOST=unix:///run/user/1000/docker.sock\" >> ~/.profile Now run source ~/.profile to refresh the environment variables. Starting the rootless docker daemon \u00b6 If you now try to run docker ps , it should result in a error as the docker daemon is not running. To start rootless docker use the following command 1 systemctl --user start docker You can now try to run docker run hello-world to test if Docker is working properly. Enable rootless docker on boot \u00b6 After you have made sure that Docker is working normally, you can run the following command to start rootless Docker on boot 1 systemctl --user enable docker Allowing binding of privileged ports \u00b6 By default on most GNU/Linux distrobutions, ports under 1000 are privileged and requires root access for changes. We can however allow the rootlesskit binary to bind privileged ports by running this command: 1 sudo setcap cap_net_bind_service = ep $HOME /bin/rootlesskit This will require a restart before the changes takes effect, applications which tries to bind privileged ports before restarting will return odd error messages. Create dedicated user/group for containers \u00b6 Create a group called homelab with the gid 1001 : 1 sudo groupadd -g 1001 homelab Create a user called docker with the uid 1001 , without any home directory: 1 sudo useradd -s /bin/bash -u 1001 -M -g homelab docker You can verify that the user and group is created with the 1001 id, by running: 1 2 grep homelab /etc/group cat /etc/passwd | grep docker We can now use 1001:1001 when starting a docker container, to make the system inside use the provided GID/UID. Which will on the host, will be translated as the user docker in the homelab group. Making it possible to restrict its access to files and folders. \"Too many open files\" Workaround \u00b6 While i was converting to rootless docker, i only had a few containers running for trying out the setup. But after trying to run my whole homelab stack in rootless, i started to see some errors related to the host's security limits. After some debugging i noticed the following limit in the dockerd process: 1 2 3 4 5 frealmyr@SRV:~$ ps aux | grep \"dockerd --experimental\" frealmyr 1225 7 .9 0 .4 1829280 74712 ? Sl 14 :46 0 :08 dockerd --experimental --storage-driver = overlay2 frealmyr@SRV:~$ cat /proc/1242/limits | grep \"Max open files\" Max open files 4096 4096 files This output tells us that dockerd process will only be allowed to have a maximum of 4096 simultaneously open files at all times. Add a few web servers and databases, and we will blast past that limit in no time, where we will end up with these kinds of errors: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 homelab: now starting Office//homer/ Starting homer ... error ERROR: for homer Cannot start service homer: failed to start shim: fork/exec /home/frealmyr/bin/containerd-shim: too many open files: unknown ERROR: for homer Cannot start service homer: failed to start shim: fork/exec /home/frealmyr/bin/containerd-shim: too many open files: unknown ERROR: Encountered errors while bringing up the project. homelab: now starting Office//kanboard/ Starting kanboard_db ... error ERROR: for kanboard_db Cannot start service postgres: failed to start shim: fork/exec /home/frealmyr/bin/containerd-shim: too many open files: unknown ERROR: for postgres Cannot start service postgres: failed to start shim: fork/exec /home/frealmyr/bin/containerd-shim: too many open files: unknown ERROR: Encountered errors while bringing up the project. What we are affected by here, is the kernel security configuration for user limits . Where the limit for \"Max open files\", is way too low for running multiple docker containers under a normal user. There are two limits, one soft that the user can decrease and one hard which sets the upper limit for the user. You can check the default limits for systemd processes by running: 1 2 3 frealmyr@SRV:~$ systemctl --user show foobar | grep LimitNOFILE LimitNOFILE = 4096 LimitNOFILESoft = 4096 Since that is too low for our purpose, let's increase the default limit for our systemd processes. Edit the /etc/systemd/system.conf file with root privileges, uncomment and update the following line: 1 DefaultLimitNOFILE = 100000 After a reboot. You can now try to run the previous command, where you should see that the default limits for number of open files have increased to 100000 : 1 2 3 frealmyr@SRV:~$ systemctl --user show foobar | grep LimitNOFILE LimitNOFILE = 100000 LimitNOFILESoft = 100000 Since the docker.service file have infinity defined for the limits in the service config, it should now have default 100000 as the limit. Which should be more than enough for a large Homelab setup. 1 2 3 4 5 frealmyr@SRV:~$ cat ${ HOME } /.config/systemd/user/docker.service | grep LimitNOFILE LimitNOFILE = infinity frealmyr@SRV:~$ cat /proc/ $( ps aux | grep \"dockerd --experimental\" | head -n1 | awk '{print $2}' ) /limits | grep \"Max open files\" Max open files 100000 100000 files You can read more about the systemd limits here: https://www.freedesktop.org/software/systemd/man/systemd.exec.html#Process%20Properties","title":"rootless docker"},{"location":"homelab/docker/rootless-docker/#deprecated","text":"I wrote this post back in 2020, Podman wasn't an alternative back then. Its mature now and I do recommend it, keeping this post as reminder for the headaches I encountered with rootless docker.","title":"\u26a0\ufe0f DEPRECATED \u26a0\ufe0f"},{"location":"homelab/docker/rootless-docker/#rootless-docker","text":"The default way to install docker is to grab the latest debian package and install it on your host using your root user. Docker will then run the daemon, containers, volumes and everything else as root . If a container is configured without any security measures and is running as root while it's publicly available. It could be a potential attack vector for gaining root access to the underlying host operating system . With these things in mind, i've recently been trying out the experimental rootless docker mode . Where the concept is to execute the Docker daemon and containers inside a user namespace, instead of running everything as root. There are however some limitations while going rootless , as the following features are not supported: AppArmor Checkpoint (Experimental) Overlay network driver Exposing SCTP ports Cgroups (hardware limits, docker top ) Non-debian based OS only supports vfs graphdriver which is considered suboptimal for many filesystems. (Overlay2 out-of-the-box on Ubuntu) One key advantage to rootless, is the ability to run docker containers inside a user namespace. Which means that you can in theory create dedicated users or groups for docker containers and make use of the host systems UIDs/GIDs for restricting access to files and features. The rootless Docker mode is still in a experimental stage. While it works rather well on my system, some bugs might arise in the future. Earlier issues like low network throughput has been fixed , so if you decide to use rootless Docker, please report any bugs or issues that you might have discovered to the relevant repositories.","title":"Rootless Docker"},{"location":"homelab/docker/rootless-docker/#installing-rootless-docker","text":"First we need to install the dependency uidmap which is needed to allow multiple UIDs/GIDs to be used in the user namespace. 1 sudo apt update && sudo apt install -f curl uidmap Now we can fetch and install the latest stable release of the rootless install script. 1 curl -fsSL https://get.docker.com/rootless | sh When the install script finishes, the output will provide some environment variable exports that will be needed by the docker-cli for connecting to the rootless docker daemon. If you run cat ~/.profile , you can see that Ubuntu automatically adds ${HOME}/bin to $PATH if the folder exists. So there is no need to add this to path manually. So we only need to add the DOCKER_HOST environment variable to our profile. 1 echo \"export DOCKER_HOST=unix:///run/user/1000/docker.sock\" >> ~/.profile Now run source ~/.profile to refresh the environment variables.","title":"Installing rootless docker"},{"location":"homelab/docker/rootless-docker/#enable-rootless-docker-on-boot","text":"After you have made sure that Docker is working normally, you can run the following command to start rootless Docker on boot 1 systemctl --user enable docker","title":"Enable rootless docker on boot"},{"location":"homelab/docker/rootless-docker/#allowing-binding-of-privileged-ports","text":"By default on most GNU/Linux distrobutions, ports under 1000 are privileged and requires root access for changes. We can however allow the rootlesskit binary to bind privileged ports by running this command: 1 sudo setcap cap_net_bind_service = ep $HOME /bin/rootlesskit This will require a restart before the changes takes effect, applications which tries to bind privileged ports before restarting will return odd error messages.","title":"Allowing binding of privileged ports"},{"location":"homelab/docker/rootless-docker/#create-dedicated-usergroup-for-containers","text":"Create a group called homelab with the gid 1001 : 1 sudo groupadd -g 1001 homelab Create a user called docker with the uid 1001 , without any home directory: 1 sudo useradd -s /bin/bash -u 1001 -M -g homelab docker You can verify that the user and group is created with the 1001 id, by running: 1 2 grep homelab /etc/group cat /etc/passwd | grep docker We can now use 1001:1001 when starting a docker container, to make the system inside use the provided GID/UID. Which will on the host, will be translated as the user docker in the homelab group. Making it possible to restrict its access to files and folders.","title":"Create dedicated user/group for containers"},{"location":"homelab/docker/rootless-docker/#too-many-open-files-workaround","text":"While i was converting to rootless docker, i only had a few containers running for trying out the setup. But after trying to run my whole homelab stack in rootless, i started to see some errors related to the host's security limits. After some debugging i noticed the following limit in the dockerd process: 1 2 3 4 5 frealmyr@SRV:~$ ps aux | grep \"dockerd --experimental\" frealmyr 1225 7 .9 0 .4 1829280 74712 ? Sl 14 :46 0 :08 dockerd --experimental --storage-driver = overlay2 frealmyr@SRV:~$ cat /proc/1242/limits | grep \"Max open files\" Max open files 4096 4096 files This output tells us that dockerd process will only be allowed to have a maximum of 4096 simultaneously open files at all times. Add a few web servers and databases, and we will blast past that limit in no time, where we will end up with these kinds of errors: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 homelab: now starting Office//homer/ Starting homer ... error ERROR: for homer Cannot start service homer: failed to start shim: fork/exec /home/frealmyr/bin/containerd-shim: too many open files: unknown ERROR: for homer Cannot start service homer: failed to start shim: fork/exec /home/frealmyr/bin/containerd-shim: too many open files: unknown ERROR: Encountered errors while bringing up the project. homelab: now starting Office//kanboard/ Starting kanboard_db ... error ERROR: for kanboard_db Cannot start service postgres: failed to start shim: fork/exec /home/frealmyr/bin/containerd-shim: too many open files: unknown ERROR: for postgres Cannot start service postgres: failed to start shim: fork/exec /home/frealmyr/bin/containerd-shim: too many open files: unknown ERROR: Encountered errors while bringing up the project. What we are affected by here, is the kernel security configuration for user limits . Where the limit for \"Max open files\", is way too low for running multiple docker containers under a normal user. There are two limits, one soft that the user can decrease and one hard which sets the upper limit for the user. You can check the default limits for systemd processes by running: 1 2 3 frealmyr@SRV:~$ systemctl --user show foobar | grep LimitNOFILE LimitNOFILE = 4096 LimitNOFILESoft = 4096 Since that is too low for our purpose, let's increase the default limit for our systemd processes. Edit the /etc/systemd/system.conf file with root privileges, uncomment and update the following line: 1 DefaultLimitNOFILE = 100000 After a reboot. You can now try to run the previous command, where you should see that the default limits for number of open files have increased to 100000 : 1 2 3 frealmyr@SRV:~$ systemctl --user show foobar | grep LimitNOFILE LimitNOFILE = 100000 LimitNOFILESoft = 100000 Since the docker.service file have infinity defined for the limits in the service config, it should now have default 100000 as the limit. Which should be more than enough for a large Homelab setup. 1 2 3 4 5 frealmyr@SRV:~$ cat ${ HOME } /.config/systemd/user/docker.service | grep LimitNOFILE LimitNOFILE = infinity frealmyr@SRV:~$ cat /proc/ $( ps aux | grep \"dockerd --experimental\" | head -n1 | awk '{print $2}' ) /limits | grep \"Max open files\" Max open files 100000 100000 files You can read more about the systemd limits here: https://www.freedesktop.org/software/systemd/man/systemd.exec.html#Process%20Properties","title":"\"Too many open files\" Workaround"},{"location":"homelab/docker/traefik/","text":"Traefik \u00b6 This is a practical guide for using Traefik v2 with docker-compose, I used this pattern previously, but have now gone all-in on Kubernetes. Create docker network \u00b6 First, lets make two docker networks dedicated to reverse proxying. One for our local network, and one for accessing externally outside our network. We seperate these, so that we can isolate applications that are accessible outside the network. Run the following commands to create the docker networks, these networks will be created in bridge mode and will persist after reboot 1 2 docker network create lab docker network create web We need to run these docker commands manually, defining these network in a docker-compose.yml will take down the networks if we run docker-compose down , which will make dependent containers fail to start. Basic traefik container \u00b6 If you have not already done it, I recommend to create a folder hierarchy for easier management of your docker-compose files, as mentioned in my introduction post. The volumes and network created by docker-compose will append the folder name to the docker resources, so in this case the internal network will be called traefik_internal . 1 2 mkdir -p $HOME /Homelab/System/traefik \\ && cd $HOME /Homelab/System/traefik Inside the traefik folder, we can now create the docker-compose.yml file for traefik 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 version : '3.5' networks : lab : external : true web : external : true internal : services : traefik : container_name : traefik image : traefik:latest environment : - TZ=Europe/Oslo ports : - 80:80 - 443:443 networks : - internal - lab - web volumes : - ./config/traefik.yml:/etc/traefik/traefik.yml - ./config/dynamic/:/etc/traefik/dynamic/ - ./config/acme.json:/etc/traefik/acme/acme.json depends_on : - docker-proxy restart : unless-stopped docker-proxy : container_name : traefik_docker_proxy image : tecnativa/docker-socket-proxy:latest # image: tecnativa/docker-socket-proxy:arm32v7 # Raspberry Pi 32-bit host networks : - internal environment : - CONTAINERS=1 volumes : - /var/run/docker.sock:/var/run/docker.sock restart : unless-stopped Line Description L3:L8 For networks, we add the docker network we created earlier as a external network. Which means that docker will try to connect to this network, but never create nor destroy it. We also have a internal network, which will only be used between services in this docker-compose. L15 Change the timezone to your current one, this will be used by things like traefik dashboard and logs. L16:L18 Traefik will bind to port 80 and 443 on the host, as this will be our primary reverse proxy. L19:L22 Here we define the networks that Traefik will connect to, we will add more networks later for other integrations. Also, L3:L8 only makes networks available for the containers. L23:L26 The traefik configuration files, mounts files in the traefik folder into the container. L28 The traefik container will not start before the docker proxy. L29 Traefik will restart on reboot, unless you stop the application with docker-compose down L31 Mounting a container to the docker API on the host is a huge security risk, so we can use a sidecar container which will make only a partion of the API accessible to the traefik container over a dedicated docker network. I highly recommend to search the web for this topic. L37 Here we can define which docker APIs that are available for read-only access, you can read more about the available APIs here . Basic Traefik configuration files \u00b6 Now that we have the docker-compose.yml in place, we need to create the configuration files for traefik, which will be mounted from the root folder into the docker container. First we need to create two folders in our traefik folder. Create a config folder and a dynamic folder inside the config folder. 1 mkdir -p config/dynamic Inside the config folder we can now create a traefik.yml file, which will be the primary config file 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 entryPoints : http : address : :80 https : address : :443 certificatesResolvers : letsEncrypt : acme : email : \"change@me.com\" storage : \"/etc/traefik/acme/acme.json\" httpChallenge : entryPoint : http providers : docker : network : lab exposedbydefault : false endpoint : \"tcp://docker-proxy:2375\" file : directory : \"/etc/traefik/dynamic/\" api : dashboard : true Line Description L1:L5 Here we define which ports Traefik should listen on. L7:L13 This bit is related to the automatic certificate generation for sites that are available externally, change the email to get warnings for expiring certificates. L17 The default docker network when configuring backends, if the app runs in another network, this needs to be overridden by a label on the container. L18 Do not expose containers when they are detected in the docker API, we need to add a traefik.enabled label to the container since this is false. L19 Traefik connects to the docker-proxy over the traefik_internal network when connecting to the docker API. L21 Traefik will monitor this directory for configuration files, and automatically reload these if there are any changes made to the files. L24 Readies the dashboard by enabling the necessary APIs, further configuration is needed. ACME certificate file \u00b6 ACME requires a dedicated acme.json file for storing its certificates, create it by running 1 touch acme.json && chmod 600 acme.json Starting Traefik \u00b6 We have now added all of the necessary static configuration files for running Traefik. We can now start Traefik to see if it is running properly 1 docker-compose up If the application starts, and there are no errors. You can close the session above, and let it run in the background 1 docker-compose up -d Now you should open up a new shell and follow the logs for the traefik container for the next steps, where you will see that traefik dynamically loads the configuration files as we edit them. 1 2 docker ps | grep traefik docker logs -f <traefik_container_id> Dynamic configuration files \u00b6 Every configuration file that you create inside the dynamic folder, will be automatically reloaded. This makes it easy to create new routing rules, as you can listen for the Traefik container logs and check the endpoint while editing files for efficient setup. Let's add two dynamic configurations, dashboard.yml for the Traefik dashboard and redirect.yml for redirecting any external sites from HTTP to HTTPS dashboard.yml : 1 2 3 4 5 6 7 8 9 http : routers : dashboard : rule : Host(`traefik.lab`) service : api@internal entryPoints : - http docker : network : lab Line Description L4 The domin where the Traefik dashboard will be available from. L5 Connects the dashboard router to the traefik api which we made available in traefik.yml L9 Dashboard will only be available from the local lab network redirect.yml : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 http : routers : http : entryPoints : - http rule : HostRegexp(`{host:.+yourexternaldomain.com}`) middlewares : - https_redirect service : noop services : noop : loadBalancer : servers : - url : http://10.0.0.33 middlewares : https_redirect : redirectScheme : scheme : https permanent : true Line Description L5 This rule applies to incoming traffic on HTTP (Port 80) L6 Only redirect traffic if its coming from yourexternaldomain.com, change to your own FQDN. L7:L8 If the L6 rule is active, use the https_redirect middleware on L17:L21 L11:L15 Services are used for forwarding traffic, since we only want to redirect the traffic to HTTPS, we set this to the host ip. L17:L21 Use the redirectScheme middleware to redirect the request from HTTP to HTTPS Folder structure after you are done \u00b6 When you are done with all the config files above, the traefik folder should look like this 1 2 3 4 5 6 7 8 9 frealmyr@FM-SRV:~/Homelab/System$ tree -L 3 traefik/ traefik/ \u251c\u2500\u2500 config \u2502 \u251c\u2500\u2500 acme.json \u2502 \u251c\u2500\u2500 dynamic \u2502 \u2502 \u251c\u2500\u2500 dashboard.yml \u2502 \u2502 \u251c\u2500\u2500 redirect.yml \u2502 \u2514\u2500\u2500 traefik.yml \u251c\u2500\u2500 docker-compose.yml Next, take a look at the Traefik Usage guide, and/or the PiHole guide for resolving .lab HTTP requests. Practical examples \u00b6 Use Case 1: Local lab network only \u00b6 Local network only example using homer , which is available from http://home.lab/, if you have setup a DNS server as i have done in the PiHole guide. Example .env enviroment file, which i use for all my Traefik applications 1 2 3 4 # Project PROJECT = home DOMAIN = lab PORT = 80 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 version : '3.5' networks : lab : external : true services : homer : container_name : homer image : b4bz/homer:latest volumes : - ./config/assets/:/www/assets - ./config/config.yml:/www/config.yml networks : - lab labels : - traefik.enable=true - traefik.http.routers.${PROJECT}.entryPoints=http - traefik.http.routers.${PROJECT}.rule=Host(`home.${DOMAIN}`) - traefik.http.services.${PROJECT}.loadbalancer.server.port=${PORT} Line Description L3:L5 We only want homer to be accessible from our lab network L14:L15 The network will be mounted by the container L17 In traefik.yaml we have set exposedbydefault: false , so we need to enable Traefik for this application L18 Tell Traefik that the entrypoint for this application is over HTTP L19 Here we define the domain that Traefik should redirect traffic to this application, which is now http://home.lab L20 This is the port that the application is listening for. If the application have a EXPOSE port defined in the Dockerfile, then Traefik should be able to auto-detect this. Use Case 2: Accessible from the internet \u00b6 Continuing with the example above, we make some slight changes 1 2 3 4 # Project PROJECT = home DOMAIN = yourdomain.com PORT = 80 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 version : '3.5' networks : web : external : true services : homer : container_name : homer image : b4bz/homer:latest volumes : - ./config/assets/:/www/assets - ./config/config.yml:/www/config.yml networks : - web labels : - traefik.enable=true - traefik.http.routers.${PROJECT}.entryPoints=https - traefik.http.routers.${PROJECT}.rule=Host(`${PROJECT}.${DOMAIN}`) - traefik.http.routers.${PROJECT}.tls.certresolver=letsEncrypt - traefik.http.services.${PROJECT}.loadbalancer.server.port=${PORT} Line Description L3:L5 Now we want homer to be accessible from the internet over the web network L14:L15 The network will be mounted by the container L17 In traefik.yaml we have set exposedbydefault: false , so we need to enable Traefik for this application L18 Tell Traefik that the entrypoint for this application is over HTTPS L19 Here we define the domain that Traefik should redirect traffic to this application, which is now https://home.yourdomain.com L20 This is the port that the application is listening for. If the application have a EXPOSE port defined in the Dockerfile, then Traefik should be able to auto-detect this.","title":"traefik"},{"location":"homelab/docker/traefik/#traefik","text":"This is a practical guide for using Traefik v2 with docker-compose, I used this pattern previously, but have now gone all-in on Kubernetes.","title":"Traefik"},{"location":"homelab/docker/traefik/#create-docker-network","text":"First, lets make two docker networks dedicated to reverse proxying. One for our local network, and one for accessing externally outside our network. We seperate these, so that we can isolate applications that are accessible outside the network. Run the following commands to create the docker networks, these networks will be created in bridge mode and will persist after reboot 1 2 docker network create lab docker network create web We need to run these docker commands manually, defining these network in a docker-compose.yml will take down the networks if we run docker-compose down , which will make dependent containers fail to start.","title":"Create docker network"},{"location":"homelab/docker/traefik/#basic-traefik-container","text":"If you have not already done it, I recommend to create a folder hierarchy for easier management of your docker-compose files, as mentioned in my introduction post. The volumes and network created by docker-compose will append the folder name to the docker resources, so in this case the internal network will be called traefik_internal . 1 2 mkdir -p $HOME /Homelab/System/traefik \\ && cd $HOME /Homelab/System/traefik Inside the traefik folder, we can now create the docker-compose.yml file for traefik 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 version : '3.5' networks : lab : external : true web : external : true internal : services : traefik : container_name : traefik image : traefik:latest environment : - TZ=Europe/Oslo ports : - 80:80 - 443:443 networks : - internal - lab - web volumes : - ./config/traefik.yml:/etc/traefik/traefik.yml - ./config/dynamic/:/etc/traefik/dynamic/ - ./config/acme.json:/etc/traefik/acme/acme.json depends_on : - docker-proxy restart : unless-stopped docker-proxy : container_name : traefik_docker_proxy image : tecnativa/docker-socket-proxy:latest # image: tecnativa/docker-socket-proxy:arm32v7 # Raspberry Pi 32-bit host networks : - internal environment : - CONTAINERS=1 volumes : - /var/run/docker.sock:/var/run/docker.sock restart : unless-stopped Line Description L3:L8 For networks, we add the docker network we created earlier as a external network. Which means that docker will try to connect to this network, but never create nor destroy it. We also have a internal network, which will only be used between services in this docker-compose. L15 Change the timezone to your current one, this will be used by things like traefik dashboard and logs. L16:L18 Traefik will bind to port 80 and 443 on the host, as this will be our primary reverse proxy. L19:L22 Here we define the networks that Traefik will connect to, we will add more networks later for other integrations. Also, L3:L8 only makes networks available for the containers. L23:L26 The traefik configuration files, mounts files in the traefik folder into the container. L28 The traefik container will not start before the docker proxy. L29 Traefik will restart on reboot, unless you stop the application with docker-compose down L31 Mounting a container to the docker API on the host is a huge security risk, so we can use a sidecar container which will make only a partion of the API accessible to the traefik container over a dedicated docker network. I highly recommend to search the web for this topic. L37 Here we can define which docker APIs that are available for read-only access, you can read more about the available APIs here .","title":"Basic traefik container"},{"location":"homelab/docker/traefik/#basic-traefik-configuration-files","text":"Now that we have the docker-compose.yml in place, we need to create the configuration files for traefik, which will be mounted from the root folder into the docker container. First we need to create two folders in our traefik folder. Create a config folder and a dynamic folder inside the config folder. 1 mkdir -p config/dynamic Inside the config folder we can now create a traefik.yml file, which will be the primary config file 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 entryPoints : http : address : :80 https : address : :443 certificatesResolvers : letsEncrypt : acme : email : \"change@me.com\" storage : \"/etc/traefik/acme/acme.json\" httpChallenge : entryPoint : http providers : docker : network : lab exposedbydefault : false endpoint : \"tcp://docker-proxy:2375\" file : directory : \"/etc/traefik/dynamic/\" api : dashboard : true Line Description L1:L5 Here we define which ports Traefik should listen on. L7:L13 This bit is related to the automatic certificate generation for sites that are available externally, change the email to get warnings for expiring certificates. L17 The default docker network when configuring backends, if the app runs in another network, this needs to be overridden by a label on the container. L18 Do not expose containers when they are detected in the docker API, we need to add a traefik.enabled label to the container since this is false. L19 Traefik connects to the docker-proxy over the traefik_internal network when connecting to the docker API. L21 Traefik will monitor this directory for configuration files, and automatically reload these if there are any changes made to the files. L24 Readies the dashboard by enabling the necessary APIs, further configuration is needed.","title":"Basic Traefik configuration files"},{"location":"homelab/docker/traefik/#starting-traefik","text":"We have now added all of the necessary static configuration files for running Traefik. We can now start Traefik to see if it is running properly 1 docker-compose up If the application starts, and there are no errors. You can close the session above, and let it run in the background 1 docker-compose up -d Now you should open up a new shell and follow the logs for the traefik container for the next steps, where you will see that traefik dynamically loads the configuration files as we edit them. 1 2 docker ps | grep traefik docker logs -f <traefik_container_id>","title":"Starting Traefik"},{"location":"homelab/docker/traefik/#dynamic-configuration-files","text":"Every configuration file that you create inside the dynamic folder, will be automatically reloaded. This makes it easy to create new routing rules, as you can listen for the Traefik container logs and check the endpoint while editing files for efficient setup. Let's add two dynamic configurations, dashboard.yml for the Traefik dashboard and redirect.yml for redirecting any external sites from HTTP to HTTPS dashboard.yml : 1 2 3 4 5 6 7 8 9 http : routers : dashboard : rule : Host(`traefik.lab`) service : api@internal entryPoints : - http docker : network : lab Line Description L4 The domin where the Traefik dashboard will be available from. L5 Connects the dashboard router to the traefik api which we made available in traefik.yml L9 Dashboard will only be available from the local lab network redirect.yml : 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 http : routers : http : entryPoints : - http rule : HostRegexp(`{host:.+yourexternaldomain.com}`) middlewares : - https_redirect service : noop services : noop : loadBalancer : servers : - url : http://10.0.0.33 middlewares : https_redirect : redirectScheme : scheme : https permanent : true Line Description L5 This rule applies to incoming traffic on HTTP (Port 80) L6 Only redirect traffic if its coming from yourexternaldomain.com, change to your own FQDN. L7:L8 If the L6 rule is active, use the https_redirect middleware on L17:L21 L11:L15 Services are used for forwarding traffic, since we only want to redirect the traffic to HTTPS, we set this to the host ip. L17:L21 Use the redirectScheme middleware to redirect the request from HTTP to HTTPS","title":"Dynamic configuration files"},{"location":"homelab/docker/traefik/#folder-structure-after-you-are-done","text":"When you are done with all the config files above, the traefik folder should look like this 1 2 3 4 5 6 7 8 9 frealmyr@FM-SRV:~/Homelab/System$ tree -L 3 traefik/ traefik/ \u251c\u2500\u2500 config \u2502 \u251c\u2500\u2500 acme.json \u2502 \u251c\u2500\u2500 dynamic \u2502 \u2502 \u251c\u2500\u2500 dashboard.yml \u2502 \u2502 \u251c\u2500\u2500 redirect.yml \u2502 \u2514\u2500\u2500 traefik.yml \u251c\u2500\u2500 docker-compose.yml Next, take a look at the Traefik Usage guide, and/or the PiHole guide for resolving .lab HTTP requests.","title":"Folder structure after you are done"},{"location":"homelab/docker/traefik/#practical-examples","text":"","title":"Practical examples"},{"location":"homelab/docker/traefik/#use-case-1-local-lab-network-only","text":"Local network only example using homer , which is available from http://home.lab/, if you have setup a DNS server as i have done in the PiHole guide. Example .env enviroment file, which i use for all my Traefik applications 1 2 3 4 # Project PROJECT = home DOMAIN = lab PORT = 80 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 version : '3.5' networks : lab : external : true services : homer : container_name : homer image : b4bz/homer:latest volumes : - ./config/assets/:/www/assets - ./config/config.yml:/www/config.yml networks : - lab labels : - traefik.enable=true - traefik.http.routers.${PROJECT}.entryPoints=http - traefik.http.routers.${PROJECT}.rule=Host(`home.${DOMAIN}`) - traefik.http.services.${PROJECT}.loadbalancer.server.port=${PORT} Line Description L3:L5 We only want homer to be accessible from our lab network L14:L15 The network will be mounted by the container L17 In traefik.yaml we have set exposedbydefault: false , so we need to enable Traefik for this application L18 Tell Traefik that the entrypoint for this application is over HTTP L19 Here we define the domain that Traefik should redirect traffic to this application, which is now http://home.lab L20 This is the port that the application is listening for. If the application have a EXPOSE port defined in the Dockerfile, then Traefik should be able to auto-detect this.","title":"Use Case 1: Local lab network only"},{"location":"homelab/docker/traefik/#use-case-2-accessible-from-the-internet","text":"Continuing with the example above, we make some slight changes 1 2 3 4 # Project PROJECT = home DOMAIN = yourdomain.com PORT = 80 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 version : '3.5' networks : web : external : true services : homer : container_name : homer image : b4bz/homer:latest volumes : - ./config/assets/:/www/assets - ./config/config.yml:/www/config.yml networks : - web labels : - traefik.enable=true - traefik.http.routers.${PROJECT}.entryPoints=https - traefik.http.routers.${PROJECT}.rule=Host(`${PROJECT}.${DOMAIN}`) - traefik.http.routers.${PROJECT}.tls.certresolver=letsEncrypt - traefik.http.services.${PROJECT}.loadbalancer.server.port=${PORT} Line Description L3:L5 Now we want homer to be accessible from the internet over the web network L14:L15 The network will be mounted by the container L17 In traefik.yaml we have set exposedbydefault: false , so we need to enable Traefik for this application L18 Tell Traefik that the entrypoint for this application is over HTTPS L19 Here we define the domain that Traefik should redirect traffic to this application, which is now https://home.yourdomain.com L20 This is the port that the application is listening for. If the application have a EXPOSE port defined in the Dockerfile, then Traefik should be able to auto-detect this.","title":"Use Case 2: Accessible from the internet"},{"location":"homelab/network/","text":"Network \u00b6 In my homelab, most of the services I host are for personal use and only available from LAN. There are also a few services that I want available from WAN, such as a public photo gallery , and for those I have a seperate traefik instance dedicated for public access. One of my goals for the homelab, is to have a somewhat production-grade cluster running, so having my public ip in a domain record should not be an issue as long as my configuration is solid. I did not want to use Cloudflare tunnel, as that service is for hosting low-bandwith services, where they clearly state in the ToS that tunneling media such as photos/video is forbidden. Makes sense that they don't want to tunnel petabytes of randoms Plex instances, just because they want their public ip proxied. (They leave their public ip all over they place when they surf the net anyway).","title":"Network"},{"location":"homelab/network/#network","text":"In my homelab, most of the services I host are for personal use and only available from LAN. There are also a few services that I want available from WAN, such as a public photo gallery , and for those I have a seperate traefik instance dedicated for public access. One of my goals for the homelab, is to have a somewhat production-grade cluster running, so having my public ip in a domain record should not be an issue as long as my configuration is solid. I did not want to use Cloudflare tunnel, as that service is for hosting low-bandwith services, where they clearly state in the ToS that tunneling media such as photos/video is forbidden. Makes sense that they don't want to tunnel petabytes of randoms Plex instances, just because they want their public ip proxied. (They leave their public ip all over they place when they surf the net anyway).","title":"Network"},{"location":"homelab/network/dns/","text":"I recommend you to get yourself a cheap domain name for personal use, it will make visiting your hosted applications a lot easier. I use Cloudflare as my dns provider since they got a solid API. The domain itself is bought elsewhere, but I have moved the dns management over to Cloudflare. I have a CNAME record for *.fmlab.no , which is a wildcard for all sub-domain requests that points to my internal IP for the server. If I want to override this for a service, I can simply create a new CNAME record for whatever.fmlab.no to override for single instances. My Cloudflare dashboard looks like this A Record server is the private ip address, traefik-internal handles reverse-proxy. This value is hardcoded. CNAME Record * is a wildcard record which points to A Record server , if a record for sub-domain does not exist, this wildcard is used. A Record vpn is the public ip, traefik-external handles reverse-proxy. This value is automatically updated by cloudflare-ddns . CNAME Record photos points to the A Record vpn , this record is managed by external-dns .","title":"DNS"},{"location":"homelab/network/reverse-proxy/","text":"What is reverse proxying? \u00b6 A reverse proxy server is a server that receives requests and forward them to the appropriate backend services. Basic example: The reverse proxy server receives a HTTP request that originated from the url http://home.lab The server checks it's configuration for any services that is configured to receive request from host.lab If this service exist, the server will redirect the traffic to this service If it doesn't exist, then it will just return a 404 not found HTTP status code Why use Traefik for reverse proxying? \u00b6 There are three obvious choices for small-scale reverse proxing; Nginx , HAProxy and Traefik . Nginx a popular reverse proxy, known for its high-performance and stability. Many have fiddled with it as a web server before, and it's quite easy to configure as a reverse proxy. The downside is that the freemium version lacks health-checks, JWT authorization, real-time metrics and dynamic reconfiguration without reloads. This is due to F5's commercial offering Nginx Plus . HAProxy is another well known reverse proxy and load balancer. It has DNS based service discovery, soft configuration reload, health checking, tons of detailed metrics, and more . It also has a fairly good reputation for on-premise Kubernetes clusters, as the developers prioritize optimization, resource efficiency and high speed networking. Traefik is a relatively new ( released 2016 ) edge router , which was created with microservices in mind. A key feature in Traefik is configuration discovery , where Traefik will query a provider API, such as the Docker API, to find relevant information and configure the routing. If you make changes to the configuration or labels on a docker container, it will dynamically update Traefik's routing configuration. You can read more about this here. Since Docker a the central component in my homelab setup, and the features that are offered out-of-box fits my use-case quite nicely. It just makes sense to use Traefik in my case. With Traefik, enabling reverse proxying for a application, is as simple as adding three labels to the docker container. If i need more middlewares on a container, like for instance, protecting an app with SSO authorization . Then i can just add another label, and Traefik will enable this for that container. Here are some neat features you get with Traefik: Auto service discovery using the Docker API Changes are reflected in realtime (No manual config reloads needed) Configuration can be written in yaml Automatic certificate issuing using LetsEncrypt Metrics (Prometheus/REST) Tracing (Jaeger/ELK) Supports TCP / UDP Lots of built-in middleware for tweaking requests before they reach the service. Such as circuit breakers , retry mechanics , rate limiting and forwardAuth for JWT authorization.","title":"Reverse Proxy"},{"location":"homelab/network/reverse-proxy/#what-is-reverse-proxying","text":"A reverse proxy server is a server that receives requests and forward them to the appropriate backend services. Basic example: The reverse proxy server receives a HTTP request that originated from the url http://home.lab The server checks it's configuration for any services that is configured to receive request from host.lab If this service exist, the server will redirect the traffic to this service If it doesn't exist, then it will just return a 404 not found HTTP status code","title":"What is reverse proxying?"},{"location":"homelab/network/reverse-proxy/#why-use-traefik-for-reverse-proxying","text":"There are three obvious choices for small-scale reverse proxing; Nginx , HAProxy and Traefik . Nginx a popular reverse proxy, known for its high-performance and stability. Many have fiddled with it as a web server before, and it's quite easy to configure as a reverse proxy. The downside is that the freemium version lacks health-checks, JWT authorization, real-time metrics and dynamic reconfiguration without reloads. This is due to F5's commercial offering Nginx Plus . HAProxy is another well known reverse proxy and load balancer. It has DNS based service discovery, soft configuration reload, health checking, tons of detailed metrics, and more . It also has a fairly good reputation for on-premise Kubernetes clusters, as the developers prioritize optimization, resource efficiency and high speed networking. Traefik is a relatively new ( released 2016 ) edge router , which was created with microservices in mind. A key feature in Traefik is configuration discovery , where Traefik will query a provider API, such as the Docker API, to find relevant information and configure the routing. If you make changes to the configuration or labels on a docker container, it will dynamically update Traefik's routing configuration. You can read more about this here. Since Docker a the central component in my homelab setup, and the features that are offered out-of-box fits my use-case quite nicely. It just makes sense to use Traefik in my case. With Traefik, enabling reverse proxying for a application, is as simple as adding three labels to the docker container. If i need more middlewares on a container, like for instance, protecting an app with SSO authorization . Then i can just add another label, and Traefik will enable this for that container. Here are some neat features you get with Traefik: Auto service discovery using the Docker API Changes are reflected in realtime (No manual config reloads needed) Configuration can be written in yaml Automatic certificate issuing using LetsEncrypt Metrics (Prometheus/REST) Tracing (Jaeger/ELK) Supports TCP / UDP Lots of built-in middleware for tweaking requests before they reach the service. Such as circuit breakers , retry mechanics , rate limiting and forwardAuth for JWT authorization.","title":"Why use Traefik for reverse proxying?"},{"location":"homelab/network/routing/","text":"I make use of netplan label functionallity for my ethernet adapter so that it can listen on two IP addresses. These two IP addresses are dedicated to public and private traffic. You can listen on multiple IP addresses, using only two is not a limt just a preference for my use-case, I tested up to 8 which worked fine. You can read more about this in the netplan docs. You can check out my configuration for this here: k8s-0-static-ip.yml I also have a second network adapter installed in my server, but this is used strictly for management of the server with its own VLAN. Useful as a fallback for when I play with networking remotely without locking myself out. LAN \u00b6 Most of the services I host are only available from local network, with firewall rules in place for allow-listed subnets. graph RL subgraph WAN [\"WAN (0.0.0.0/24)\"] user((client)) -->|request| svc[argocd.fmlab.no] end subgraph LAN [LAN 10.0.0.0/24] svc -->|CNAME 10.8.0.10| server[/enp3s0:private 10.8.0.10\\] server --> traefik(traefik-internal) traefik -->|response| user; end style LAN fill:#282a36 style WAN fill:#282a36 style user fill:#6272a4; linkStyle 0 stroke:green; linkStyle 1 stroke:green; linkStyle 2 stroke:green; linkStyle 3 stroke:yellow; For accessing these services outside my network, I use Wireguard VPN. WAN \u00b6 A few services is available from WAN, these services gets their own DNS CNAME Records which points to my external IP. graph RL subgraph WAN [\"WAN (0.0.0.0/24)\"] user((client)) -->|request| svc[argocd.fmlab.no] end subgraph LAN [\"LAN (10.0.0.0/24)\"] svc -->|CNAME 120.110.0.123| router[\"Router TP-Link R605\"] router -->|\"Port-forward\"| server[/enp3s0:public 10.8.0.11\\] server --> traefik(traefik-external) traefik -->|response| user; end style LAN fill:#282a36 style WAN fill:#282a36 style user fill:#6272a4; linkStyle 0 stroke:green; linkStyle 1 stroke:green; linkStyle 2 stroke:green; linkStyle 3 stroke:yellow; linkStyle 4 stroke:yellow; These services have a CNAME record which points to my public ip, my router port-forwards this traffic to the public network adapter on my server. The public traefik instance then reverse-proxy the request based on the requested sub-domain.","title":"Routing"},{"location":"homelab/network/routing/#lan","text":"Most of the services I host are only available from local network, with firewall rules in place for allow-listed subnets. graph RL subgraph WAN [\"WAN (0.0.0.0/24)\"] user((client)) -->|request| svc[argocd.fmlab.no] end subgraph LAN [LAN 10.0.0.0/24] svc -->|CNAME 10.8.0.10| server[/enp3s0:private 10.8.0.10\\] server --> traefik(traefik-internal) traefik -->|response| user; end style LAN fill:#282a36 style WAN fill:#282a36 style user fill:#6272a4; linkStyle 0 stroke:green; linkStyle 1 stroke:green; linkStyle 2 stroke:green; linkStyle 3 stroke:yellow; For accessing these services outside my network, I use Wireguard VPN.","title":"LAN"},{"location":"homelab/network/routing/#wan","text":"A few services is available from WAN, these services gets their own DNS CNAME Records which points to my external IP. graph RL subgraph WAN [\"WAN (0.0.0.0/24)\"] user((client)) -->|request| svc[argocd.fmlab.no] end subgraph LAN [\"LAN (10.0.0.0/24)\"] svc -->|CNAME 120.110.0.123| router[\"Router TP-Link R605\"] router -->|\"Port-forward\"| server[/enp3s0:public 10.8.0.11\\] server --> traefik(traefik-external) traefik -->|response| user; end style LAN fill:#282a36 style WAN fill:#282a36 style user fill:#6272a4; linkStyle 0 stroke:green; linkStyle 1 stroke:green; linkStyle 2 stroke:green; linkStyle 3 stroke:yellow; linkStyle 4 stroke:yellow; These services have a CNAME record which points to my public ip, my router port-forwards this traffic to the public network adapter on my server. The public traefik instance then reverse-proxy the request based on the requested sub-domain.","title":"WAN"},{"location":"synology/","text":"Synology \u00b6","title":"Synology"},{"location":"synology/#synology","text":"","title":"Synology"},{"location":"synology/docker/setup/","text":"Docker Setup & Pattern \u00b6 To make our docker configuration simple, clean and secure we are going to do the following: Install docker using the Container Manager package Create a folder structure with a category pattern Create dedicated users for docker containers Create a share dedicated for docker-compose shares Use the docker-compose functionality introduced in DSM 7.2 I'll assume you know how to to do basic configuration in Synology DSM, such as creating shares, installing packages, etc. M.2 SSD Array \u00b6 I recommend you to install docker on a dedicated M.2 SSD, even if your device does not officially support it. You can do this at a later date and keep the data when moving the package over to the M.2 SSD volume. Docker on M.2 benefits includes lower latency when accessing applications, less random access on spinning disk array, less wakeups on HDDs if you hibernate. Setup \u00b6 Install the Container Manager package from the Package Center. This will automatically create the share docker on the Volume you selected (or set as default) in Package Center. The docker share will contain docker volumes, which will be used if you define a named volume . Useful when you want to persist data in a centralized location on the host, such as taking backup of all docker volumes. Normal users will not need access to this share, only services which will make backups from docker volumes. Stacks \u00b6 We need a share for storing docker-compose stacks, which contains docker-compose.yml definitions, optional .env files and possibly bind mounts if we want to keep configuration close to the stack. docker-compose prefixes the current folder to the docker containers, so we need a bottom level folder with the name of the stack. Else docker ps will become ugly. Create the stack share, grant your standard user read/write permissions for the share. Add the share to your local machine, open up the share in an IDE. Folder pattern \u00b6 I recommend the following folder pattern: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 stacks \u251c\u2500\u2500 Data \u2502 \u2514\u2500\u2500 duplicati \u2502 \u2514\u2500\u2500 docker-compose.yml \u251c\u2500\u2500 Entertainment \u2502 \u251c\u2500\u2500 jellyfin \u2502 \u2502 \u251c\u2500\u2500 config \u2502 \u2502 \u2514\u2500\u2500 docker-compose.yml \u2502 \u2514\u2500\u2500 yarr \u2502 \u251c\u2500\u2500 .env \u2502 \u251c\u2500\u2500 config \u2502 \u2514\u2500\u2500 docker-compose.yml \u2514\u2500\u2500 System \u2514\u2500\u2500 watchtower \u2514\u2500\u2500 docker-compose.yml This will seperate a set of stacks under a category, which scales well when the number of stacks grow. Starting a stack \u00b6 Create the following folders on the stacks share: 1 2 3 4 stacks \u2514\u2500\u2500 System \u2514\u2500\u2500 watchtower \u2514\u2500\u2500 docker-compose.yml Create the docker-compose.yml with the following content: Watchtower is a application for auto-upgrading all docker container images using the Docker API. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 version : \"3.5\" networks : internal : services : watchtower : container_name : watchtower image : containrrr/watchtower:latest networks : - internal environment : - TZ=Europe/Oslo - WATCHTOWER_CLEANUP=true volumes : - /var/run/docker.sock:/var/run/docker.sock restart : unless-stopped We are now ready to start the docker-compose.yml stack, and you got two options. CLI \u00b6 SSH into the NAS using your admin user cd /volume2/stacks cd System/watchtower docker-compose up -d docker ps or docker-compose ps GUI \u00b6 There are two limitations with GUI. You cannot create folders when selecting location and no support for .env files for using variables inside docker-compose.yml Users \u00b6 By default, Docker containers run with root access to the host system. We can make it more secure by defining linux users with standard access that the different containers will use. Setting user id is ad-hoc between the host and the container. We can set define which user id and group id to use inside the container, say 1000:1000 , which will not have access for files on the host as the user 1000 does not exist on the host, nor has the permission for accessing the files. Setting UID/GID is either done in the docker run command, during docker image build, or as a pre-step script in the entrypoint using environment variables. So we basically need to: Create a standard user in DSM Optional: grant access to shares for the standard user to use SSH into the nas with admin user Run id -u USERNAME and id -g USERNAME to get UID and GID values Set the UID and GID on the container configuration","title":"Setup"},{"location":"synology/docker/setup/#docker-setup-pattern","text":"To make our docker configuration simple, clean and secure we are going to do the following: Install docker using the Container Manager package Create a folder structure with a category pattern Create dedicated users for docker containers Create a share dedicated for docker-compose shares Use the docker-compose functionality introduced in DSM 7.2 I'll assume you know how to to do basic configuration in Synology DSM, such as creating shares, installing packages, etc.","title":"Docker Setup &amp; Pattern"},{"location":"synology/docker/setup/#m2-ssd-array","text":"I recommend you to install docker on a dedicated M.2 SSD, even if your device does not officially support it. You can do this at a later date and keep the data when moving the package over to the M.2 SSD volume. Docker on M.2 benefits includes lower latency when accessing applications, less random access on spinning disk array, less wakeups on HDDs if you hibernate.","title":"M.2 SSD Array"},{"location":"synology/docker/setup/#setup","text":"Install the Container Manager package from the Package Center. This will automatically create the share docker on the Volume you selected (or set as default) in Package Center. The docker share will contain docker volumes, which will be used if you define a named volume . Useful when you want to persist data in a centralized location on the host, such as taking backup of all docker volumes. Normal users will not need access to this share, only services which will make backups from docker volumes.","title":"Setup"},{"location":"synology/docker/setup/#stacks","text":"We need a share for storing docker-compose stacks, which contains docker-compose.yml definitions, optional .env files and possibly bind mounts if we want to keep configuration close to the stack. docker-compose prefixes the current folder to the docker containers, so we need a bottom level folder with the name of the stack. Else docker ps will become ugly. Create the stack share, grant your standard user read/write permissions for the share. Add the share to your local machine, open up the share in an IDE.","title":"Stacks"},{"location":"synology/docker/setup/#folder-pattern","text":"I recommend the following folder pattern: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 stacks \u251c\u2500\u2500 Data \u2502 \u2514\u2500\u2500 duplicati \u2502 \u2514\u2500\u2500 docker-compose.yml \u251c\u2500\u2500 Entertainment \u2502 \u251c\u2500\u2500 jellyfin \u2502 \u2502 \u251c\u2500\u2500 config \u2502 \u2502 \u2514\u2500\u2500 docker-compose.yml \u2502 \u2514\u2500\u2500 yarr \u2502 \u251c\u2500\u2500 .env \u2502 \u251c\u2500\u2500 config \u2502 \u2514\u2500\u2500 docker-compose.yml \u2514\u2500\u2500 System \u2514\u2500\u2500 watchtower \u2514\u2500\u2500 docker-compose.yml This will seperate a set of stacks under a category, which scales well when the number of stacks grow.","title":"Folder pattern"},{"location":"synology/docker/setup/#starting-a-stack","text":"Create the following folders on the stacks share: 1 2 3 4 stacks \u2514\u2500\u2500 System \u2514\u2500\u2500 watchtower \u2514\u2500\u2500 docker-compose.yml Create the docker-compose.yml with the following content: Watchtower is a application for auto-upgrading all docker container images using the Docker API. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 version : \"3.5\" networks : internal : services : watchtower : container_name : watchtower image : containrrr/watchtower:latest networks : - internal environment : - TZ=Europe/Oslo - WATCHTOWER_CLEANUP=true volumes : - /var/run/docker.sock:/var/run/docker.sock restart : unless-stopped We are now ready to start the docker-compose.yml stack, and you got two options.","title":"Starting a stack"},{"location":"synology/docker/setup/#cli","text":"SSH into the NAS using your admin user cd /volume2/stacks cd System/watchtower docker-compose up -d docker ps or docker-compose ps","title":"CLI"},{"location":"synology/docker/setup/#gui","text":"There are two limitations with GUI. You cannot create folders when selecting location and no support for .env files for using variables inside docker-compose.yml","title":"GUI"},{"location":"synology/docker/setup/#users","text":"By default, Docker containers run with root access to the host system. We can make it more secure by defining linux users with standard access that the different containers will use. Setting user id is ad-hoc between the host and the container. We can set define which user id and group id to use inside the container, say 1000:1000 , which will not have access for files on the host as the user 1000 does not exist on the host, nor has the permission for accessing the files. Setting UID/GID is either done in the docker run command, during docker image build, or as a pre-step script in the entrypoint using environment variables. So we basically need to: Create a standard user in DSM Optional: grant access to shares for the standard user to use SSH into the nas with admin user Run id -u USERNAME and id -g USERNAME to get UID and GID values Set the UID and GID on the container configuration","title":"Users"},{"location":"synology/docker/stacks/jellyfin/","text":"Jellyfin \u00b6 Users \u00b6 Create the following users in Synology DSM: jellyfin SSH into the NAS with admin user, and get the id for the user and group: 1 2 id -u jellyfin id -g jellyfin Shares \u00b6 Grant the Jellyfin user read only access to the entertainment share. If you have yet to create it, see the yarr docs. Stack \u00b6 Create the following files and folders under the stack share: docker-compose.yml \u00b6 Remember to change the user: to the id of your jellyfin user. 1 2 3 4 5 stacks \u2514\u2500\u2500 Entertainment \u2514\u2500\u2500 jellyfin \u251c\u2500\u2500 config/ \u2514\u2500\u2500 docker-compose.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 version : '3.5' services : jellyfin : container_name : jellyfin image : jellyfin/jellyfin:latest user : 10xx:100 group_add : - \"937\" # Group on host for allowing jellyfin access to hardware encoding/decoding volumes : - ./config:/config - /volume1/entertainment:/volume1/entertainment:ro devices : - /dev/dri/card0:/dev/dri/card0 - /dev/dri/renderD128:/dev/dri/renderD128 network_mode : host restart : unless-stopped","title":"jellyfin"},{"location":"synology/docker/stacks/jellyfin/#jellyfin","text":"","title":"Jellyfin"},{"location":"synology/docker/stacks/jellyfin/#users","text":"Create the following users in Synology DSM: jellyfin SSH into the NAS with admin user, and get the id for the user and group: 1 2 id -u jellyfin id -g jellyfin","title":"Users"},{"location":"synology/docker/stacks/jellyfin/#shares","text":"Grant the Jellyfin user read only access to the entertainment share. If you have yet to create it, see the yarr docs.","title":"Shares"},{"location":"synology/docker/stacks/jellyfin/#stack","text":"Create the following files and folders under the stack share:","title":"Stack"},{"location":"synology/docker/stacks/jellyfin/#docker-composeyml","text":"Remember to change the user: to the id of your jellyfin user. 1 2 3 4 5 stacks \u2514\u2500\u2500 Entertainment \u2514\u2500\u2500 jellyfin \u251c\u2500\u2500 config/ \u2514\u2500\u2500 docker-compose.yml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 version : '3.5' services : jellyfin : container_name : jellyfin image : jellyfin/jellyfin:latest user : 10xx:100 group_add : - \"937\" # Group on host for allowing jellyfin access to hardware encoding/decoding volumes : - ./config:/config - /volume1/entertainment:/volume1/entertainment:ro devices : - /dev/dri/card0:/dev/dri/card0 - /dev/dri/renderD128:/dev/dri/renderD128 network_mode : host restart : unless-stopped","title":"docker-compose.yml"},{"location":"synology/docker/stacks/yarr/","text":"yarr \u00b6 Users \u00b6 Create the following users in Synology DSM: yarr SSH into the NAS with admin user, and get the id for the user and group: 1 2 id -u yarr id -g yarr Shares \u00b6 Create the following shares, with read/write permissions for the yarr user. entertainment downloads I recommend to use a M.2 SSD volume for the download share, and use sonarr / radarr to copy completed downloads to the entertainment share. As seeding is quite heavy on random read, this will lessen the burden on HDD and increase their lifespan. Stack \u00b6 Create the following files and folders under the stack share: 1 2 3 4 5 6 stacks \u2514\u2500\u2500 Entertainment \u2514\u2500\u2500 yarr \u251c\u2500\u2500 .env \u251c\u2500\u2500 config/ \u2514\u2500\u2500 docker-compose.yml The config/ folder will be used by all applications for storing configurations, which is handy to have close to the docker-compose stack. .env \u00b6 Populate the .env file with the following content: 1 2 3 4 PUID = 10xx PGID = 100 TIMEZONE = Europe/Oslo EXTERNAL_IP = 192 .168.0.11 Replace PUID with the id for your own yarr user! EXTERNAL_IP is used for only listening for connections on the second ethernet port, with the idea that the first port is used for NAS transfers and the second for Docker stuff. Can be removed if you remove the variable and colon in the docker-compose.yml file docker-compose.yml \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 version : '3.5' networks : internal : services : transmission : image : lscr.io/linuxserver/transmission:latest container_name : transmission environment : - PUID=${PUID} - PGID=${PGID} - TZ=${TIMEZONE} - PEERPORT=54213 volumes : - ./config/transmission:/config - /volume2/downloads:/volume2/downloads - /volume1/entertainment:/volume1/entertainment networks : - internal ports : - ${EXTERNAL_IP}:9091:9091 - ${EXTERNAL_IP}:54213:54213 - ${EXTERNAL_IP}:54213:54213/udp restart : unless-stopped prowlarr : container_name : prowlarr image : lscr.io/linuxserver/prowlarr:develop environment : - PUID=${PUID} - PGID=${PGID} - TZ=${TIMEZONE} volumes : - ./config/prowlarr:/config networks : - internal ports : - ${EXTERNAL_IP}:9696:9696 restart : unless-stopped sonarr : container_name : sonarr image : linuxserver/sonarr:latest environment : - PUID=${PUID} - PGID=${PGID} - TZ=${TIMEZONE} volumes : - ./config/sonarr:/config - /volume2/downloads:/volume2/downloads - /volume1/entertainment:/volume1/entertainment networks : - internal ports : - ${EXTERNAL_IP}:8989:8989 depends_on : - prowlarr restart : unless-stopped radarr : container_name : radarr image : linuxserver/radarr:latest environment : - PUID=${PUID} - PGID=${PGID} - TZ=${TIMEZONE} volumes : - ./config/radarr:/config - /volume2/downloads:/volume2/downloads - /volume1/entertainment:/volume1/entertainment networks : - internal ports : - ${EXTERNAL_IP}:7878:7878 depends_on : - prowlarr restart : unless-stopped \u00b6","title":"yarr"},{"location":"synology/docker/stacks/yarr/#yarr","text":"","title":"yarr"},{"location":"synology/docker/stacks/yarr/#users","text":"Create the following users in Synology DSM: yarr SSH into the NAS with admin user, and get the id for the user and group: 1 2 id -u yarr id -g yarr","title":"Users"},{"location":"synology/docker/stacks/yarr/#shares","text":"Create the following shares, with read/write permissions for the yarr user. entertainment downloads I recommend to use a M.2 SSD volume for the download share, and use sonarr / radarr to copy completed downloads to the entertainment share. As seeding is quite heavy on random read, this will lessen the burden on HDD and increase their lifespan.","title":"Shares"},{"location":"synology/docker/stacks/yarr/#stack","text":"Create the following files and folders under the stack share: 1 2 3 4 5 6 stacks \u2514\u2500\u2500 Entertainment \u2514\u2500\u2500 yarr \u251c\u2500\u2500 .env \u251c\u2500\u2500 config/ \u2514\u2500\u2500 docker-compose.yml The config/ folder will be used by all applications for storing configurations, which is handy to have close to the docker-compose stack.","title":"Stack"},{"location":"synology/docker/stacks/yarr/#env","text":"Populate the .env file with the following content: 1 2 3 4 PUID = 10xx PGID = 100 TIMEZONE = Europe/Oslo EXTERNAL_IP = 192 .168.0.11 Replace PUID with the id for your own yarr user! EXTERNAL_IP is used for only listening for connections on the second ethernet port, with the idea that the first port is used for NAS transfers and the second for Docker stuff. Can be removed if you remove the variable and colon in the docker-compose.yml file","title":".env"},{"location":"synology/docker/stacks/yarr/#docker-composeyml","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 version : '3.5' networks : internal : services : transmission : image : lscr.io/linuxserver/transmission:latest container_name : transmission environment : - PUID=${PUID} - PGID=${PGID} - TZ=${TIMEZONE} - PEERPORT=54213 volumes : - ./config/transmission:/config - /volume2/downloads:/volume2/downloads - /volume1/entertainment:/volume1/entertainment networks : - internal ports : - ${EXTERNAL_IP}:9091:9091 - ${EXTERNAL_IP}:54213:54213 - ${EXTERNAL_IP}:54213:54213/udp restart : unless-stopped prowlarr : container_name : prowlarr image : lscr.io/linuxserver/prowlarr:develop environment : - PUID=${PUID} - PGID=${PGID} - TZ=${TIMEZONE} volumes : - ./config/prowlarr:/config networks : - internal ports : - ${EXTERNAL_IP}:9696:9696 restart : unless-stopped sonarr : container_name : sonarr image : linuxserver/sonarr:latest environment : - PUID=${PUID} - PGID=${PGID} - TZ=${TIMEZONE} volumes : - ./config/sonarr:/config - /volume2/downloads:/volume2/downloads - /volume1/entertainment:/volume1/entertainment networks : - internal ports : - ${EXTERNAL_IP}:8989:8989 depends_on : - prowlarr restart : unless-stopped radarr : container_name : radarr image : linuxserver/radarr:latest environment : - PUID=${PUID} - PGID=${PGID} - TZ=${TIMEZONE} volumes : - ./config/radarr:/config - /volume2/downloads:/volume2/downloads - /volume1/entertainment:/volume1/entertainment networks : - internal ports : - ${EXTERNAL_IP}:7878:7878 depends_on : - prowlarr restart : unless-stopped","title":"docker-compose.yml"},{"location":"synology/docker/stacks/yarr/#_1","text":"","title":""},{"location":"workstation/","text":"Workstation \u00b6 My current workstation is a Lenovo Carbon X1 Gen 9","title":"Workstation"},{"location":"workstation/#workstation","text":"My current workstation is a Lenovo Carbon X1 Gen 9","title":"Workstation"},{"location":"workstation/configuration/dotfiles/","text":"Dotfiles \u00b6 I make use of a bare git repository for my dotfiles, which is a git repository without a working tree and copies of checked out files. This results in the possibility to have a folder named ~/.dotfiles , which keeps track of only my committed configuration files in my home folder, without any hacky symlinks. Basically, this allows me to make my home folder a git repository, where I only keep track of checked in files, ignoring untracked files when using git commands. I make use of a alias for managing the dotfiles 1 alias dotfiles = '/usr/bin/git --git-dir=$HOME/.dotfiles/ --work-tree=$HOME' Example commands \u00b6 Downloading the latest commit 1 dotfiles pull Using a different branch for dotfiles 1 dotfiles checkout x11/i3 Add / edit files, then push commit to dotfiles repository 1 2 3 4 dotfiles status dotfiles add .vimrc dotfiles commit -m \"add vimrc\" dotfiles push origin wayland/sway Use ssh instead of https \u00b6 Ansible playbooks configures my dotfiles with https by default. Due to my new ssh key is not present in github during setup. 1 dotfiles remote set-url origin git@github.com:frealmyr/dotfiles-configs.git","title":"dotfiles"},{"location":"workstation/configuration/dotfiles/#dotfiles","text":"I make use of a bare git repository for my dotfiles, which is a git repository without a working tree and copies of checked out files. This results in the possibility to have a folder named ~/.dotfiles , which keeps track of only my committed configuration files in my home folder, without any hacky symlinks. Basically, this allows me to make my home folder a git repository, where I only keep track of checked in files, ignoring untracked files when using git commands. I make use of a alias for managing the dotfiles 1 alias dotfiles = '/usr/bin/git --git-dir=$HOME/.dotfiles/ --work-tree=$HOME'","title":"Dotfiles"},{"location":"workstation/configuration/dotfiles/#example-commands","text":"Downloading the latest commit 1 dotfiles pull Using a different branch for dotfiles 1 dotfiles checkout x11/i3 Add / edit files, then push commit to dotfiles repository 1 2 3 4 dotfiles status dotfiles add .vimrc dotfiles commit -m \"add vimrc\" dotfiles push origin wayland/sway","title":"Example commands"},{"location":"workstation/configuration/dotfiles/#use-ssh-instead-of-https","text":"Ansible playbooks configures my dotfiles with https by default. Due to my new ssh key is not present in github during setup. 1 dotfiles remote set-url origin git@github.com:frealmyr/dotfiles-configs.git","title":"Use ssh instead of https"},{"location":"workstation/configuration/smb-automount/","text":"SMB auto-mount \u00b6 Mounting SMB automatically on a Unix system is not-so-forward, navigating posts from stackoverflow and forums will most likely result in trying out old and deprecated solutions. Here are my experiences with mounting samba shares: cifs is the newer implementation for the smb proctocol in the kernel. The older smbfs is deprecated, without any maintainers and is only available due to backwards compability. Credentials for cifs basically requires a plaintext file containing username= and password= which is referenced during mount, which is truly horrifying security wise. Creating a file at /root/.smbcredentials with chmod 0600 permissions is as secure as it gets. If you got a better alternative, please reach out. Kerberos does not look like a sane solution for single-users. autofs is deprecated and superseeded by the systemd module remote-fs . Be careful mounting remote locations in /etc/stab , as they will not work when you are not in your local network. In worst case, it will make your computer panic during boot. Follow principle of least privilege, create a seperate user on the smb server with access to only the folders that you are going to mount. Here is a example of a line I use in /etc/fstab 1 //nas.fmlab.no/media /mnt/nas/media cifs _netdev,vers = 3 ,x-systemd.automount,x-systemd.idle-timeout = 15min,rw,dir_mode = 0775 ,file_mode = 0664 ,iocharset = utf8,uid = fredrick,gid = users,credentials = /root/.smbcredentials 0 0 Breakdown of the flags used: Flag Description _netdev wait for networking service to start before attempting this mount vers=3 use SMBv3.0 protocol version and above x-systemd.automount establish remote connection to share and mount only when local directory is accessed x-systemd.idle-timeout=15min unmount share if the local directory has not been accessed for over x minutes rw enable read-write access on remote share dir_mode=0775 default directory permission file_mode=0664 default file permission iocharset=utf8 allows access to files with names in non-English languages uid=fredrick makes the user owner of the mounted share gid=users makes the group owner of the mounted share credentials=/root/.smbcredentials path to credentials file which contains lines with username= and password= , can be stored in home dir, recommend permission 600 on file for security. This requires a credentials file stored in /root containing your smb credentials 1 2 3 4 sudo tee /root/.smbcredentials > /dev/null <<EOT username= password= EOT Set the permission to 0600 so that only root can access it 1 sudo chmod 0600 /root/.smbcredentials To reload entries in /etc/fstab , run the following command 1 sudo systemctl daemon-reload && sudo systemctl restart remote-fs.target We don't need to use mount -a , as systemd will automatically mount the remote folder when you access the local folder, the command will work, but systemd will unmount the folder when the idle-timeout for the share is activated. You should now be able to see the files from the remote share in the local folder you specified in /etc/fstab , such as navigating to /mnt/nas/media in the example above. Debugging \u00b6 The following command will monitor kernel logs, where CIFS errors should be present 1 dmesg -w Errors here can be a bit cryptic. I found out that error -13 can be a indicator for a credentials file misconfiguration,. After making changes to /etc/fstab or the credentials file, restart the systemd component for remote-fs 1 sudo systemctl daemon-reload && sudo systemctl restart remote-fs.target If all is well, dmesg should output the following 1 2 3 4 [ 35 .934212 ] Key type dns_resolver registered [ 36 .015220 ] Key type cifs.spnego registered [ 36 .015231 ] Key type cifs.idmap registered [ 36 .015848 ] CIFS: Attempting to mount \\\\ nas.fmlab.no \\m edia","title":"smb auto-mount"},{"location":"workstation/configuration/smb-automount/#smb-auto-mount","text":"Mounting SMB automatically on a Unix system is not-so-forward, navigating posts from stackoverflow and forums will most likely result in trying out old and deprecated solutions. Here are my experiences with mounting samba shares: cifs is the newer implementation for the smb proctocol in the kernel. The older smbfs is deprecated, without any maintainers and is only available due to backwards compability. Credentials for cifs basically requires a plaintext file containing username= and password= which is referenced during mount, which is truly horrifying security wise. Creating a file at /root/.smbcredentials with chmod 0600 permissions is as secure as it gets. If you got a better alternative, please reach out. Kerberos does not look like a sane solution for single-users. autofs is deprecated and superseeded by the systemd module remote-fs . Be careful mounting remote locations in /etc/stab , as they will not work when you are not in your local network. In worst case, it will make your computer panic during boot. Follow principle of least privilege, create a seperate user on the smb server with access to only the folders that you are going to mount. Here is a example of a line I use in /etc/fstab 1 //nas.fmlab.no/media /mnt/nas/media cifs _netdev,vers = 3 ,x-systemd.automount,x-systemd.idle-timeout = 15min,rw,dir_mode = 0775 ,file_mode = 0664 ,iocharset = utf8,uid = fredrick,gid = users,credentials = /root/.smbcredentials 0 0 Breakdown of the flags used: Flag Description _netdev wait for networking service to start before attempting this mount vers=3 use SMBv3.0 protocol version and above x-systemd.automount establish remote connection to share and mount only when local directory is accessed x-systemd.idle-timeout=15min unmount share if the local directory has not been accessed for over x minutes rw enable read-write access on remote share dir_mode=0775 default directory permission file_mode=0664 default file permission iocharset=utf8 allows access to files with names in non-English languages uid=fredrick makes the user owner of the mounted share gid=users makes the group owner of the mounted share credentials=/root/.smbcredentials path to credentials file which contains lines with username= and password= , can be stored in home dir, recommend permission 600 on file for security. This requires a credentials file stored in /root containing your smb credentials 1 2 3 4 sudo tee /root/.smbcredentials > /dev/null <<EOT username= password= EOT Set the permission to 0600 so that only root can access it 1 sudo chmod 0600 /root/.smbcredentials To reload entries in /etc/fstab , run the following command 1 sudo systemctl daemon-reload && sudo systemctl restart remote-fs.target We don't need to use mount -a , as systemd will automatically mount the remote folder when you access the local folder, the command will work, but systemd will unmount the folder when the idle-timeout for the share is activated. You should now be able to see the files from the remote share in the local folder you specified in /etc/fstab , such as navigating to /mnt/nas/media in the example above.","title":"SMB auto-mount"},{"location":"workstation/configuration/smb-automount/#debugging","text":"The following command will monitor kernel logs, where CIFS errors should be present 1 dmesg -w Errors here can be a bit cryptic. I found out that error -13 can be a indicator for a credentials file misconfiguration,. After making changes to /etc/fstab or the credentials file, restart the systemd component for remote-fs 1 sudo systemctl daemon-reload && sudo systemctl restart remote-fs.target If all is well, dmesg should output the following 1 2 3 4 [ 35 .934212 ] Key type dns_resolver registered [ 36 .015220 ] Key type cifs.spnego registered [ 36 .015231 ] Key type cifs.idmap registered [ 36 .015848 ] CIFS: Attempting to mount \\\\ nas.fmlab.no \\m edia","title":"Debugging"},{"location":"workstation/laptop/lenovo-x1-gen9/","text":"Lenovo X1 Carbon Gen 9 \u00b6 https://www.lenovo.com/us/en/p/laptops/thinkpad/thinkpadx1/x1-carbon-gen9/22tp2x1x1c9 Intel Graphics \u00b6 The iGPU is gen 12, which has new features called GuC and HuC built-in that have power usage and performance benefits. When enabled, my laptop runs cooler, gained 3-4 hours of battery with the same usage pattern, hardware acceleration also seems to work better in firefox/chromium. These features are not enabled by default, as the official intel docs states that they are not available on < gen12 intel CPUs. However, this laptop have a gen11 CPU, while the iGPU is gen12 and the features works properly when enabled. There is currently a mailing list for enabling these features by default for this CPU. https://wiki.archlinux.org/title/Talk:Intel_graphics#TGL/RKL_GuC_Submission All credit to inslee@askfedora: https://ask.fedoraproject.org/t/intel-graphics-best-practices-and-settings-for-hardware-acceleration/21119 Sound issues \u00b6 This laptop have a 4 speaker array for Dobly Atmos support. The factory installed firmware had buggy support for these speakers in Linux based OS, the sound was muffled and sounded like mono-channel, volume was also low and using amplification just made the sound even worse. Turns out there was a firmware update for the audio controller available, after installing this with fw-update all of my issues went away and now my speakers are fantastic in Linux.","title":"Lenovo X1 Carbon Gen 9"},{"location":"workstation/laptop/lenovo-x1-gen9/#lenovo-x1-carbon-gen-9","text":"https://www.lenovo.com/us/en/p/laptops/thinkpad/thinkpadx1/x1-carbon-gen9/22tp2x1x1c9","title":"Lenovo X1 Carbon Gen 9"},{"location":"workstation/laptop/lenovo-x1-gen9/#intel-graphics","text":"The iGPU is gen 12, which has new features called GuC and HuC built-in that have power usage and performance benefits. When enabled, my laptop runs cooler, gained 3-4 hours of battery with the same usage pattern, hardware acceleration also seems to work better in firefox/chromium. These features are not enabled by default, as the official intel docs states that they are not available on < gen12 intel CPUs. However, this laptop have a gen11 CPU, while the iGPU is gen12 and the features works properly when enabled. There is currently a mailing list for enabling these features by default for this CPU. https://wiki.archlinux.org/title/Talk:Intel_graphics#TGL/RKL_GuC_Submission All credit to inslee@askfedora: https://ask.fedoraproject.org/t/intel-graphics-best-practices-and-settings-for-hardware-acceleration/21119","title":"Intel Graphics"},{"location":"workstation/laptop/lenovo-x1-gen9/#sound-issues","text":"This laptop have a 4 speaker array for Dobly Atmos support. The factory installed firmware had buggy support for these speakers in Linux based OS, the sound was muffled and sounded like mono-channel, volume was also low and using amplification just made the sound even worse. Turns out there was a firmware update for the audio controller available, after installing this with fw-update all of my issues went away and now my speakers are fantastic in Linux.","title":"Sound issues"}]}